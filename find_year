import spacy
import re
import pandas as pd

nlp = spacy.load("en_core_web_sm")  # 較小模型以節省資源

def create_match_rules(word_list, noun_terms=None):
    word_list = word_list + noun_terms
    match_rules = []
    noun_terms = set(noun_terms or [])
    for item in word_list:
        item = item.strip().lower()
        if item in noun_terms:
            match_rules.append({"type": "keyword", "value": item})
        elif " " in item:
            parts = item.split()
            if len(parts) == 2:
                match_rules.append({"type": "phrasal", "value": (parts[0], parts[1])})
        elif "-" in item or item.endswith("out") or item.endswith("over"):
            match_rules.append({"type": "compound", "value": item})
        else:
            match_rules.append({"type": "lemma", "value": item})
    return match_rules

def analyze_text_with_flags(df, columns_name ,raw_keywords, noun_terms, flag_label, strict_mode=True):
    match_rules = create_match_rules(raw_keywords, noun_terms)

    # Extract years
    df['years'] = df[columns_name].str.findall(r"\b(19[0-9]{2}|20[0-9]{2})\b")
    df['years_count'] = df['years'].apply(len)

    # Apply spaCy
    docs = list(nlp.pipe(df[columns_name].tolist()))
    df['spacy_data'] = [{
        'doc': doc,
        'token_info': [(t.text, t.lemma_, t.pos_, t.dep_, t.i) for t in doc],
        'entity_info': [(e.text, e.label_, e.start) for e in doc.ents]
    } for doc in docs]
    df['token_info'] = df['spacy_data'].apply(lambda x: x['token_info'])
    df['entity_info'] = df['spacy_data'].apply(lambda x: x['entity_info'])

    def analyze_row(row):
        tokens = row['token_info']
        ents = row['entity_info']
        doc = row['spacy_data']['doc']
        years = row['years']
        years_count = row['years_count']

        token_texts = [t[0].lower() for t in tokens]
        lemmas = [t[1].lower() for t in tokens]

        important_indices = []
        match_keyword = False
        match_noun = False
        match_org = False

        for i, (text_tok, lemma, pos, _, idx) in enumerate(tokens):
            for rule in match_rules:
                if rule["type"] == "lemma" and lemma == rule["value"] and pos in ["VERB", "NOUN"]:
                    important_indices.append(idx)
                    match_keyword = True
                elif rule["type"] == "compound" and (text_tok == rule["value"] or lemma == rule["value"]):
                    important_indices.append(idx)
                    match_keyword = True
                elif rule["type"] == "keyword" and (lemma == rule["value"] or text_tok == rule["value"]):
                    important_indices.append(idx)
                    match_noun = True

        for rule in match_rules:
            if rule["type"] == "phrasal":
                for i in range(len(tokens) - 1):
                    if (lemmas[i], token_texts[i + 1]) == rule["value"]:
                        important_indices.extend([tokens[i][4], tokens[i + 1][4]])
                        match_keyword = True

        excluded_subjects = {"government", "ministry", "department", "agency", "council"}
        for org_text, label, start in ents:
            if label == "ORG" and org_text.lower() not in excluded_subjects:
                match_org = True
                important_indices.append(start)

        fallback_orgs = ["apple", "microsoft", "tesla", "amazon", "google"]
        if not match_org:
            for token in token_texts:
                if token in fallback_orgs:
                    match_org = True

        if not match_noun:
            has_excluded_subject = any(
                lemma in excluded_subjects and dep in {"nsubj", "nsubjpass"}
                for _, lemma, _, dep, _ in tokens
            )
        else:
            has_excluded_subject = False

        closest_year = None
        if years and important_indices:
            closest_year = min(
                years,
                key=lambda y: min(
                    [abs(token.i - idx) for idx in important_indices for token in doc if token.text == y],
                    default=float('inf')
                )
            )

        # 新增語態分析
        voice = "unknown"
        for _, _, _, dep, _ in tokens:
            if dep == "nsubjpass":
                voice = "passive"
                break
            elif dep == "nsubj":
                voice = "active"

        if strict_mode:
            if match_keyword and (match_noun or match_org) and years_count > 0 and not has_excluded_subject:
                return flag_label, closest_year, voice
        else:
            if match_keyword and years_count > 0:
                return flag_label, closest_year, voice

        return "", None, voice

    df[['flag', 'closest_year', 'voice']] = df.apply(analyze_row, axis=1, result_type='expand')
    return df

# 測試資料
df = pd.DataFrame({
    'text': [
        "Apple is looking at buying a U.K. startup for $1 billion.",
        "Elon Musk founded SpaceX and Tesla.",
        "The Eiffel Tower is located in Paris.",
        "This site gained control over the market and expanded in 1980.",
        "This firm gained control of the industry in 1990, and by 2000 it was dominating.",
        "In 2020, this site was gaining control rapidly, and the company saw growth in 2021.",
        "They gained control of the market in 2015, but faced challenges in 2020.",
        "This firm gains control every year, and in 2025, it plans to expand further.",
        "Microsoft gained control in 1995 and continued to grow.",
        "Apple gained control of the market in 2001, and by 2005, it was a leader.",
        "Control was procured by the firm in 1997, and they were able to grow rapidly in 2000.",
        "In 2023, they were buying out smaller firms.",
        "In 2024, the firm completed a buyout of its main competitor.",
        "They finalized the acquisition in 2019.",
        "The government took possession of the land in 2010.",
        "The government said that the site took possession of the land in 2010.",
        "This site was dominating the market since 2001.",
        "They moved to a new office in 2020.",
        "We may consider a merger by 2023.",
        "Move operations to Europe in 2024.",
    ]
})

# 執行分析
df_result = analyze_text_with_flags(
    df, 'text',
    raw_keywords=[
        "gain", "purchase", "procure", "acquire", "buy", "merge", "take", "control",
        "buyout", "buy-out", "bought-out", "acquisition",
        "buy out", "take over", "gain control", "take possession"
    ],
    noun_terms=["site", "firm"],
    flag_label="cata",
    strict_mode=True
)

# 顯示結果
df_result
