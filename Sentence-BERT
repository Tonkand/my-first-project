
ğŸ“¦ å®Œæ•´å¥å­ç›¸ä¼¼åº¦æ¨¡å‹ Pipeline

âœ… åŠŸèƒ½èªªæ˜ï¼š
1. åˆ©ç”¨ Sentence-BERT å¾®èª¿æ¨¡å‹ï¼Œå­¸ç¿’èªæ„ç›¸ä¼¼åº¦
2. åŒæ™‚ä¿ç•™èªæ³•åˆ†æï¼ˆPOS / ä¾å­˜é—œä¿‚ï¼‰ä½œç‚ºè¼”åŠ©ç‰¹å¾µ
3. å¯æŸ¥æ‰¾æ–°æ®µè½ä¸­çš„å¥å­æ˜¯å¦èˆ‡è¨“ç·´å¥å­ç›¸åŒ/ç›¸ä¼¼

ğŸ”§ ä¸€ã€å®‰è£å¥—ä»¶
pip install sentence-transformers faiss-cpu spacy scikit-learn pandas nltk
python -m spacy download en_core_web_sm

ğŸ§  äºŒã€æº–å‚™è¨“ç·´è³‡æ–™ï¼ˆå¥å° + ç›¸ä¼¼åº¦ï¼‰

from sentence_transformers import InputExample

# æ¨¡æ“¬ä¸€äº›ç›¸ä¼¼/ä¸ç›¸ä¼¼çš„å¥å­å°
train_data = [
    InputExample(texts=["She bought a new car.", "She purchased a new car."], label=0.95),
    InputExample(texts=["The site was acquired in 2010.", "In 2010, the site was purchased."], label=0.9),
    InputExample(texts=["He is going to the store.", "She is staying home."], label=0.1),
]

ğŸ—ï¸ ä¸‰ã€æ¨¡å‹å¾®èª¿

from sentence_transformers import SentenceTransformer, losses
from torch.utils.data import DataLoader

model = SentenceTransformer('all-MiniLM-L6-v2')  # å°æ¨¡å‹ä¹Ÿå¾ˆå¥½ç”¨

train_dataloader = DataLoader(train_data, shuffle=True, batch_size=4)
train_loss = losses.CosineSimilarityLoss(model)

model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    epochs=2,
    warmup_steps=10,
    show_progress_bar=True
)

model.save("semantic_syntax_model")

ğŸ§ª å››ã€æŸ¥è©¢ï¼šæ‰¾å‡ºç›¸ä¼¼å¥å­

from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹
model = SentenceTransformer("semantic_syntax_model")

# åŸå§‹èªæ–™ï¼ˆå‘é‡åº«ï¼‰
corpus_sentences = [
    "She bought a new car.",
    "The site was acquired in 2010.",
    "He is going to the store.",
]
corpus_embeddings = model.encode(corpus_sentences)

# è¦æŸ¥çš„æ–°æ®µè½
new_text = "In 2010, the site was purchased. She purchased a car yesterday."

import nltk
nltk.download('punkt')
from nltk.tokenize import sent_tokenize

query_sentences = sent_tokenize(new_text)
query_embeddings = model.encode(query_sentences)

# æ¯”å°ç›¸ä¼¼åº¦
for i, (query, emb) in enumerate(zip(query_sentences, query_embeddings)):
    sims = cosine_similarity([emb], corpus_embeddings)[0]
    best_idx = np.argmax(sims)
    best_score = sims[best_idx]
    if best_score > 0.7:
        print(f"ğŸŸ¡ é¡ä¼¼å¥å­: {query}")
        print(f"   ğŸ”— æœ€ç›¸ä¼¼: {corpus_sentences[best_idx]}")
        print(f"   ğŸ”¢ ç›¸ä¼¼åº¦: {best_score:.4f}\n")
    else:
        print(f"âœ… ä¸ç›¸ä¼¼å¥å­: {query}\n")

ğŸ§  äº”ã€å¯é¸åŠ å¼·ï¼šåŠ å…¥èªæ³•è³‡è¨Šï¼ˆPOS / dependencyï¼‰

import spacy
nlp = spacy.load("en_core_web_sm")

doc = nlp("She purchased a new car.")
print("POS tags:", [token.pos_ for token in doc])
print("Dependencies:", [token.dep_ for token in doc])
