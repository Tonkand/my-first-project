################
####
################
import spacy
from pyspark.sql import SparkSession
from pyspark.sql.functions import udf, explode
from pyspark.sql.types import StructType, StructField, StringType, ArrayType

# 初始化 Spark 與 spaCy
spark = SparkSession.builder.appName("ParentSubsidiaryExtractor").getOrCreate()
nlp = spacy.load("en_core_web_sm")

# 關鍵詞集合
ownership_keywords = {
    "acquire", "acquired", "buy", "bought", "purchase", "purchased", "take over",
    "taken over", "merge", "merged", "merged with", "absorb", "absorbed",
    "acquisition", "takeover", "was bought by", "was acquired by"
}
structure_keywords = {
    "own", "owns", "subsidiary of", "parent company", "ultimate owner", "holding company"
}
all_keywords = ownership_keywords.union(structure_keywords)

# UDF：輸入段落 → 拆句 → 擷取公司與角色
def extract_entities_with_roles(paragraph):
    results = []
    if not paragraph:
        return results

    doc = nlp(paragraph)
    for sent in doc.sents:
        sentence = sent.text.strip()
        lower = sentence.lower()

        if not any(kw in lower for kw in all_keywords):
            continue

        # spaCy ORG 實體
        orgs = [ent for ent in sent.ents if ent.label_ == "ORG"]

        # 若沒抓到 → fallback: 手動猜測可能的公司詞
        if not orgs:
            guessed = []
            for token in sent:
                if (
                    token.text[0].isupper()
                    and token.pos_ in ("PROPN", "NOUN")
                    and len(token.text) > 2
                    and token.text.lower() not in {"firm", "company", "group"}
                ):
                    guessed.append(token.text)
            if guessed:
                orgs = [spacy.tokens.Span(doc, token.i, token.i+1, label="ORG")
                        for token in sent if token.text in guessed]

        # 判斷每個 ORG 的角色
        for ent in orgs:
            label = None
            for token in sent:
                if ent.start <= token.i <= ent.end:
                    if token.dep_ in ("nsubj", "nsubjpass"):
                        label = "parent"
                    elif token.dep_ in ("dobj", "pobj", "attr", "appos"):
                        label = "subsidiary"
                    break
            if not label:
                label = "parent" if sentence.find(ent.text) < len(sentence) / 2 else "subsidiary"

            results.append((sentence, ent.text, label))

    return results

# 註冊 Spark UDF
schema = ArrayType(StructType([
    StructField("sentence", StringType(), True),
    StructField("company", StringType(), True),
    StructField("role", StringType(), True)
]))
extract_udf = udf(extract_entities_with_roles, schema)

# 測試段落資料
data = [
    ("NVIDIA bought this firm. No useful info here. Meta owns Instagram.",),
    ("Google was acquired by Alphabet. The parent company of Apple is Apple Inc.",)
]
df = spark.createDataFrame(data, ["paragraph"])

# 執行轉換
df_result = df.withColumn("entities", extract_udf("paragraph"))
df_final = df_result.select(explode("entities").alias("entity_info"))
df_final = df_final.selectExpr(
    "entity_info.sentence",
    "entity_info.company",
    "entity_info.role"
)

# 顯示結果
df_final.show(truncate=False)


#########

import spacy
from pyspark.sql import SparkSession
from pyspark.sql.functions import udf, explode
from pyspark.sql.types import StructType, StructField, StringType, ArrayType

# 初始化 Spark 與 spaCy
spark = SparkSession.builder.appName("ParentSubsidiaryExtractor").getOrCreate()
nlp = spacy.load("en_core_web_sm")

# 關鍵詞集合
ownership_keywords = {
    "acquire", "acquired", "buy", "bought", "purchase", "purchased", "take over",
    "taken over", "merge", "merged", "merged with", "absorb", "absorbed",
    "acquisition", "takeover", "was bought by", "was acquired by"
}
structure_keywords = {
    "own", "owns", "subsidiary of", "parent company", "ultimate owner", "holding company"
}
all_keywords = ownership_keywords.union(structure_keywords)

# 主體邏輯 UDF：輸入段落 → 拆句 → 找公司 → 分角色
def extract_entities_with_roles(paragraph):
    results = []
    if not paragraph:
        return results

    doc = nlp(paragraph)
    for sent in doc.sents:
        sentence = sent.text.strip()
        lower = sentence.lower()

        has_keyword = any(kw in lower for kw in all_keywords)

        # 對該句辨識出 PERSON 與 ORG
        person_names = set(ent.text for ent in sent.ents if ent.label_ == "PERSON")
        orgs = [ent for ent in sent.ents if ent.label_ == "ORG"]

        # fallback：如果沒抓到 ORG，但有關鍵字 → 嘗試猜測
        if not orgs and has_keyword:
            guessed = []
            for token in sent:
                if (
                    token.text[0].isupper()
                    and token.pos_ in ("PROPN", "NOUN")
                    and len(token.text) > 2
                    and token.text.lower() not in {"firm", "company", "group"}
                ):
                    guessed.append(token.text)
            # 去除人名
            guessed = [g for g in guessed if g not in person_names]

            # 模擬為 ORG 實體
            if guessed:
                orgs = [spacy.tokens.Span(doc, token.i, token.i+1, label="ORG")
                        for token in sent if token.text in guessed]

        # 判斷每個 ORG 的角色
        if has_keyword and orgs:
            for ent in orgs:
                label = None
                for token in sent:
                    if ent.start <= token.i <= ent.end:
                        if token.dep_ in ("nsubj", "nsubjpass"):
                            label = "parent"
                        elif token.dep_ in ("dobj", "pobj", "attr", "appos"):
                            label = "subsidiary"
                        break
                if not label:
                    label = "parent" if sentence.find(ent.text) < len(sentence) / 2 else "subsidiary"
                results.append((sentence, ent.text, label))
        else:
            # 沒公司或關鍵詞也保留句子，空值填空
            results.append((sentence, "", ""))

    return results

# 註冊 Spark UDF
schema = ArrayType(StructType([
    StructField("sentence", StringType(), True),
    StructField("company", StringType(), True),
    StructField("role", StringType(), True)
]))
extract_udf = udf(extract_entities_with_roles, schema)

# 測試資料
data = [
    ("NVIDIA bought this firm. No useful info here. Meta owns Instagram.",),
    ("Google was acquired by Alphabet. The parent company of Apple is Apple Inc.",),
    ("The firm was found in 2021 by Mr. Yongjun Tu who is the owner of the company.",)
]
df = spark.createDataFrame(data, ["paragraph"])

# 套用 UDF
df_result = df.withColumn("entities", extract_udf("paragraph"))
df_final = df_result.select(explode("entities").alias("entity_info"))
df_final = df_final.selectExpr(
    "entity_info.sentence",
    "entity_info.company",
    "entity_info.role"
)

# 顯示結果
df_final.show(truncate=False)


