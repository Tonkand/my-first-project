################
####
################
import spacy
from pyspark.sql import SparkSession
from pyspark.sql.functions import udf, explode
from pyspark.sql.types import StructType, StructField, StringType, ArrayType

# 初始化 Spark 與 spaCy
spark = SparkSession.builder.appName("ParentSubsidiaryExtractor").getOrCreate()
nlp = spacy.load("en_core_web_sm")

# 關鍵詞集合
ownership_keywords = {
    "acquire", "acquired", "buy", "bought", "purchase", "purchased", "take over",
    "taken over", "merge", "merged", "merged with", "absorb", "absorbed",
    "acquisition", "takeover", "was bought by", "was acquired by"
}
structure_keywords = {
    "own", "owns", "subsidiary of", "parent company", "ultimate owner", "holding company"
}
all_keywords = ownership_keywords.union(structure_keywords)

# UDF：輸入段落 → 拆句 → 擷取公司與角色
def extract_entities_with_roles(paragraph):
    results = []
    if not paragraph:
        return results

    doc = nlp(paragraph)
    for sent in doc.sents:
        sentence = sent.text.strip()
        lower = sentence.lower()

        if not any(kw in lower for kw in all_keywords):
            continue

        # spaCy ORG 實體
        orgs = [ent for ent in sent.ents if ent.label_ == "ORG"]

        # 若沒抓到 → fallback: 手動猜測可能的公司詞
        if not orgs:
            guessed = []
            for token in sent:
                if (
                    token.text[0].isupper()
                    and token.pos_ in ("PROPN", "NOUN")
                    and len(token.text) > 2
                    and token.text.lower() not in {"firm", "company", "group"}
                ):
                    guessed.append(token.text)
            if guessed:
                orgs = [spacy.tokens.Span(doc, token.i, token.i+1, label="ORG")
                        for token in sent if token.text in guessed]

        # 判斷每個 ORG 的角色
        for ent in orgs:
            label = None
            for token in sent:
                if ent.start <= token.i <= ent.end:
                    if token.dep_ in ("nsubj", "nsubjpass"):
                        label = "parent"
                    elif token.dep_ in ("dobj", "pobj", "attr", "appos"):
                        label = "subsidiary"
                    break
            if not label:
                label = "parent" if sentence.find(ent.text) < len(sentence) / 2 else "subsidiary"

            results.append((sentence, ent.text, label))

    return results

# 註冊 Spark UDF
schema = ArrayType(StructType([
    StructField("sentence", StringType(), True),
    StructField("company", StringType(), True),
    StructField("role", StringType(), True)
]))
extract_udf = udf(extract_entities_with_roles, schema)

# 測試段落資料
data = [
    ("NVIDIA bought this firm. No useful info here. Meta owns Instagram.",),
    ("Google was acquired by Alphabet. The parent company of Apple is Apple Inc.",)
]
df = spark.createDataFrame(data, ["paragraph"])

# 執行轉換
df_result = df.withColumn("entities", extract_udf("paragraph"))
df_final = df_result.select(explode("entities").alias("entity_info"))
df_final = df_final.selectExpr(
    "entity_info.sentence",
    "entity_info.company",
    "entity_info.role"
)

# 顯示結果
df_final.show(truncate=False)


#########

import spacy
from pyspark.sql import SparkSession
from pyspark.sql.functions import udf, explode
from pyspark.sql.types import StructType, StructField, StringType, ArrayType

# 初始化 Spark 和 spaCy
spark = SparkSession.builder.appName("ParentSubsidiaryExtractor").getOrCreate()
nlp = spacy.load("en_core_web_sm")

# 關鍵詞集合
ownership_keywords = {
    "acquire", "acquired", "buy", "bought", "purchase", "purchased", "take over",
    "taken over", "merge", "merged", "merged with", "absorb", "absorbed",
    "acquisition", "takeover", "was bought by", "was acquired by"
}
structure_keywords = {
    "own", "owns", "subsidiary of", "parent company", "ultimate owner", "holding company"
}
all_keywords = ownership_keywords.union(structure_keywords)

# 稱謂詞
title_words = {"mr.", "mrs.", "ms.", "dr.", "prof.", "miss", "sir", "madam"}

# 判斷是否是人名前綴
def is_title_name(token, sent):
    i = token.i
    if i > 0:
        prev = sent[i - 1].text.lower()
        if prev in title_words:
            return True
    return False

# 主邏輯：切句、抽公司、分類、過濾人名與稱謂
def extract_entities_with_roles(paragraph):
    results = []
    if not paragraph:
        return results

    doc = nlp(paragraph)
    for sent in doc.sents:
        sentence = sent.text.strip()
        lower = sentence.lower()

        has_keyword = any(kw in lower for kw in all_keywords)

        person_names = set(ent.text for ent in sent.ents if ent.label_ == "PERSON")
        orgs = [ent for ent in sent.ents if ent.label_ == "ORG"]

        # fallback：猜測可能公司
        if not orgs and has_keyword:
            guessed = []
            for token in sent:
                if (
                    token.text[0].isupper()
                    and token.pos_ in ("PROPN", "NOUN")
                    and len(token.text) > 2
                    and token.text.lower() not in {"firm", "company", "group"}
                    and token.text not in person_names
                    and not is_title_name(token, sent)
                    and token.text.lower() not in title_words
                ):
                    guessed.append(token.text)
            if guessed:
                orgs = [spacy.tokens.Span(doc, token.i, token.i+1, label="ORG")
                        for token in sent if token.text in guessed]

        # 判斷角色
        if has_keyword and orgs:
            for ent in orgs:
                label = None
                for token in sent:
                    if ent.start <= token.i <= ent.end:
                        if token.dep_ in ("nsubj", "nsubjpass"):
                            label = "parent"
                        elif token.dep_ in ("dobj", "pobj", "attr", "appos"):
                            label = "subsidiary"
                        break
                if not label:
                    label = "parent" if sentence.find(ent.text) < len(sentence) / 2 else "subsidiary"
                results.append((sentence, ent.text, label))
        else:
            # 保留句子，但公司與角色為空
            results.append((sentence, "", ""))

    return results

# 註冊 UDF
schema = ArrayType(StructType([
    StructField("sentence", StringType(), True),
    StructField("company", StringType(), True),
    StructField("role", StringType(), True)
]))
extract_udf = udf(extract_entities_with_roles, schema)

# 測試資料
data = [
    ("NVIDIA bought this firm. No useful info here. Meta owns Instagram.",),
    ("Google was acquired by Alphabet. The parent company of Apple is Apple Inc.",),
    ("The firm was found in 2021 by Mr. Yongjun Tu who is the owner of the company.",)
]
df = spark.createDataFrame(data, ["paragraph"])

# 執行流程
df_result = df.withColumn("entities", extract_udf("paragraph"))
df_final = df_result.select(explode("entities").alias("entity_info"))
df_final = df_final.selectExpr(
    "entity_info.sentence",
    "entity_info.company",
    "entity_info.role"
)

# 顯示結果
df_final.show(truncate=False)

