from nltk.corpus import wordnet
import nltk
nltk.download('wordnet')

def get_noun_derivations(word):
    nouns = set()
    for syn in wordnet.synsets(word):
        for lemma in syn.lemmas():
            for related_form in lemma.derivationally_related_forms():
                if related_form.synset().pos() == 'n':
                    nouns.add(related_form.name().replace("_", " "))
    return list(nouns)

# 示例
print(get_noun_derivations("decide"))  # ['decision', 'deciding', 'decider']
print(get_noun_derivations("employ"))  # ['employment', 'employer', 'employee']
print(get_noun_derivations("fail"))    # ['failure']



#############
import nltk
from nltk.corpus import wordnet as wn

# 如果还没有下载 wordnet，可以先运行一次下面这行
# nltk.download('wordnet')

def get_noun_forms(word):
    noun_forms = set()
    for synset in wn.synsets(word):
        for lemma in synset.lemmas():
            # 遍历派生关系
            for deriv in lemma.derivationally_related_forms():
                if deriv.synset().pos() == 'n':  # 只保留名词
                    noun_forms.add(deriv.name())
    return list(noun_forms)

# 示例
word = "inform"
print(get_noun_forms(word))


#########
import nltk
from nltk.corpus import wordnet as wn

def get_direct_noun_forms(word):
    noun_forms = set()
    word = word.lower()
    for synset in wn.synsets(word, pos=wn.VERB):  # 只从动词的同义词集合找
        for lemma in synset.lemmas():
            for deriv in lemma.derivationally_related_forms():
                name = deriv.name().lower()
                if deriv.synset().pos() == 'n' and name.startswith(word[:3]):
                    noun_forms.add(name)
    return list(noun_forms)

# 示例
print(get_direct_noun_forms("fail"))

#####phrase

import spacy
import nltk
import inflect
from nltk.corpus import wordnet as wn

# 初始化工具
nlp = spacy.load("en_core_web_sm")
p = inflect.engine()

# 确保 wordnet 可用
# nltk.download('wordnet')

def get_derived_nouns(word):
    noun_forms = set()
    for synset in wn.synsets(word):
        for lemma in synset.lemmas():
            for related in lemma.derivationally_related_forms():
                if related.synset().pos() == 'n':
                    noun_forms.add(related.name())
    return noun_forms

def extract_all_noun_candidates(phrase):
    doc = nlp(phrase)
    result = {}

    for token in doc:
        if token.pos_ in {"NOUN", "VERB", "PROPN"}:
            lemma = token.lemma_.lower()
            noun_set = get_derived_nouns(lemma)
            noun_set.add(lemma)

            # 加入复数形式
            plural_form = p.plural(lemma)
            if plural_form != lemma:
                noun_set.add(plural_form)

            result[token.text] = sorted(noun_set)

    return result

# 示例使用
phrase = "sampling area"
output = extract_all_noun_candidates(phrase)
for word, forms in output.items():
    print(f"{word} → {forms}")


