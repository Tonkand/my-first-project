from nltk.corpus import wordnet
import nltk
nltk.download('wordnet')

def get_noun_derivations(word):
    nouns = set()
    for syn in wordnet.synsets(word):
        for lemma in syn.lemmas():
            for related_form in lemma.derivationally_related_forms():
                if related_form.synset().pos() == 'n':
                    nouns.add(related_form.name().replace("_", " "))
    return list(nouns)

# 示例
print(get_noun_derivations("decide"))  # ['decision', 'deciding', 'decider']
print(get_noun_derivations("employ"))  # ['employment', 'employer', 'employee']
print(get_noun_derivations("fail"))    # ['failure']



#############
import nltk
from nltk.corpus import wordnet as wn

# 如果还没有下载 wordnet，可以先运行一次下面这行
# nltk.download('wordnet')

def get_noun_forms(word):
    noun_forms = set()
    for synset in wn.synsets(word):
        for lemma in synset.lemmas():
            # 遍历派生关系
            for deriv in lemma.derivationally_related_forms():
                if deriv.synset().pos() == 'n':  # 只保留名词
                    noun_forms.add(deriv.name())
    return list(noun_forms)

# 示例
word = "inform"
print(get_noun_forms(word))


#########
import nltk
from nltk.corpus import wordnet as wn

def get_direct_noun_forms(word):
    noun_forms = set()
    word = word.lower()
    for synset in wn.synsets(word, pos=wn.VERB):  # 只从动词的同义词集合找
        for lemma in synset.lemmas():
            for deriv in lemma.derivationally_related_forms():
                name = deriv.name().lower()
                if deriv.synset().pos() == 'n' and name.startswith(word[:3]):
                    noun_forms.add(name)
    return list(noun_forms)

# 示例
print(get_direct_noun_forms("fail"))

#####phrase

import spacy
import nltk
from nltk.corpus import wordnet as wn

# 加载 spaCy 英文模型
nlp = spacy.load("en_core_web_sm")

# 如果还没下载 wordnet，可以先运行
# nltk.download('wordnet')

def get_noun_forms(word):
    forms = set()
    for synset in wn.synsets(word, pos=wn.NOUN):
        for lemma in synset.lemmas():
            forms.add(lemma.name())
    return forms

def extract_noun_forms_from_phrase(phrase):
    doc = nlp(phrase)
    noun_forms_map = {}

    for token in doc:
        if token.pos_ == "NOUN":
            lemma = token.lemma_.lower()
            forms = get_noun_forms(lemma)
            forms.add(lemma)
            noun_forms_map[token.text] = list(forms)
    return noun_forms_map

# 示例
phrase = "sampling area"
result = extract_noun_forms_from_phrase(phrase)
print(result)

